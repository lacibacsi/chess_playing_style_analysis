{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a03451",
   "metadata": {},
   "source": [
    "## Data pre-preparation code \n",
    "this notebook is mainly used for data preparation... \n",
    "main goal is to be reproducible for the main notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56ce61",
   "metadata": {},
   "source": [
    "### Control parameters for the calculations\n",
    "The below settings how players will be included or excluded based on their games history as well as what it the minumum number of games for a country to be used in the geographical analysis. It also contains the settings for running mode (use url or local files, save / load temporary calculations and whether to use test data instead of the large non-test files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_years_seen = 1  #number of years a player has to have games for analysis\n",
    "minimum_games = 10 #number of games a player has to have across all the years seen\n",
    "minimum_games_country = 50 #number of games for a country to be displayed in the geographical analysis\n",
    "\n",
    "#if set to true only samples will be loaded not the full datasets\n",
    "testmode = True\n",
    "\n",
    "#if set to true precalculated data will be loaded from the saved files\n",
    "use_prepared_data = False\n",
    "\n",
    "#if true, when not using generated data interim results will be saved\n",
    "#please note, when doing precalculation data will only be saved locally\n",
    "save_prepared_data = False\n",
    "\n",
    "# if true the files will be read / grabbed from the urls - second and third items in the file name lists\n",
    "# otherwise local sources will be read - source files need to be in the same directory as the notebook\n",
    "use_urls = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659bfac",
   "metadata": {},
   "source": [
    "### Constants, helpers and other functions\n",
    "This section contains functions that are either reused in multiple places or just don't belong to any of the sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4866d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810aa3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders where source files and the precalculated ones are stored - to be able to manually check contents\n",
    "url_source_files: 'https://drive.google.com/drive/folders/15wEVKEMiNeuZSfXBMS4B72IcLDnGU-np/'\n",
    "url_precalced: 'https://drive.google.com/drive/folders/1RMeA5K3y5_QPG10UE3-CDM-lL8iSD3hG/'\n",
    "\n",
    "#default directory. the environment has to have geopandas installed and configured\n",
    "#given the kernel may run in a different environment, start:\n",
    "# jupyter notebook --notebook-dir=/Users/laszlokovari/Documents/personal/leeds/Programming/Assignments/ChessAnalysis/notebook/\n",
    "\n",
    "#default file names to load and save\n",
    "#each filename contains 3 values: [local file name, url for full data, url for sample data]\n",
    "players_fn = ['Players', 'https://drive.google.com/uc?id=1XryDU569ecgU0X573DivDpBJgUzABh3N','https://drive.google.com/uc?id=13qWhq0QfhxVWT3OWct8TK0NOmqwUZqlp']\n",
    "ratings_early_fn = ['RatingsRanksTitlesearlier',\n",
    "                    's3://chessanalysis/RatingsRanksTitlesearlier.csv',\n",
    "                    'https://drive.google.com/uc?id=1L29Q-Gcdl2bEnm-zX_Z4s-wfRrlJmZ3A']\n",
    "\n",
    "ratings_late_fn = ['Ratingsrankstitleslater',\n",
    "                   's3://chessanalysis/Ratingsrankstitleslater.csv'\n",
    "                   ,'s3://chessanalysis/Ratingsrankstitleslater.csv']\n",
    "eco_codes_fn = ['eco_codes','https://drive.google.com/uc?id=1v8STV2upc5GLp3jBI3mCR0tyHjaaTuPs','https://drive.google.com/uc?id=1JzAbo9vcda8PBMNJlxZi22_AHHEXTpyo']\n",
    "#games csv file - assumes already converted data from pgn\n",
    "games_fn = ['games',\n",
    "            's3://chessanalysis/games.csv',\n",
    "            'https://drive.google.com/uc?id=18bDYt6VWRrcQ06xJA_bUhGVezy57J7s9'] \n",
    "country_codes = ['countries_codes','https://drive.google.com/uc?id=1MLXgBnyamK64TRlM9eiwxou7Lc4KiVSe','https://drive.google.com/uc?id=1HRvSFlK2NbcQ5_pLydx9ivM0FDlD2MNy'] \n",
    "    \n",
    "#file names for precalculated files\n",
    "ratings_early_grouped_fn = ['ratings_early_grouped', 'https://drive.google.com/uc?id=10eyrCoG7HXEhuoZsipA4hoT8w5ilfnij','https://drive.google.com/uc?id=1YGj6_O6bUWUwef71PlMI6w3cwu_r_KQV']                            \n",
    "ratings_later_grouped_fn = ['ratings_later_grouped', 'https://drive.google.com/uc?id=19rWxoXo3EZpa2mI21cGI_l4IM1Dfby06','https://drive.google.com/uc?id=1bwlf9L4WkTVCNTOKTcCRVlqyk18odbjk']                            \n",
    "players_with_rating_fn = ['players_with_rating','https://drive.google.com/uc?id=1an1m6iRDyTZz_q0GKPeojDTXEAIMl-X4','https://drive.google.com/uc?id=146gmSIghbNNrLccjgyHPj5gvHKfnSoY4']\n",
    "id_year_grouped_games = ['yearly_grouped_games_for_id','https://drive.google.com/uc?id=1pgArvy4RDCbTSIsGqsC-lh4__P2uR9kT','https://drive.google.com/uc?id=1uwdb6VIfeeQJoXHOfMjOInDQXkr9rzid']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the filename based on whether the code runs in test more or not. By default it will return csv extension\n",
    "#only relevant when in local mode, urls will contain all the details\n",
    "def getfilename(fn, extension = 'csv'):\n",
    "    \"\"\"\n",
    "        Returns the filename / url of the input filename list\n",
    "        if url are used the second or third item of the relevant filename list is returned \n",
    "        for non-test / test respectively, \n",
    "        otherwise the first item (optionally with _sample added) and the extension is returned for local processing\n",
    "    \"\"\"\n",
    "    if use_urls:\n",
    "        if testmode:\n",
    "            return fn[2]\n",
    "        return fn[1]\n",
    "    \n",
    "    if testmode:\n",
    "        fn = fn + '_sample'\n",
    "    if extension == 'csv':\n",
    "        fn = fn + '.csv'\n",
    "    else:\n",
    "        fn = fn + '.' + extension\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea86698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefile(filename, df):\n",
    "    \"\"\"\n",
    "        Saves a files as UTF-8 encoded file\n",
    "        \n",
    "        Input:  filename, dataframe\n",
    "        Output: none\n",
    "    \"\"\"\n",
    "    \n",
    "    df.to_csv(filename, sep=',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc096503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadfile(filename, separator = ','):\n",
    "    \"\"\"\n",
    "        Loads a file and returns the dataframe read from it\n",
    "        It assumes that the filename contains all the necessary details, i.e. url, token, querystring etc.\n",
    "        \n",
    "        Input:  filename\n",
    "        Output: dataframe with the file contents\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename, sep=separator, encoding = 'utf-8')\n",
    "    return df\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec16179",
   "metadata": {},
   "source": [
    "### Dataframe and chart functions\n",
    "The below functions are used across multiple dataframes and include methods to add new columns, calculate columns during grouping. This section also contains the chart generation functions as there are many parameters and this keeps the notebook somewhat less cluttered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f30e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_totals(df):\n",
    "    df['total_sharp'] = df['sharp_white'] + df['sharp_black']\n",
    "    df['total'] = df['total_white'] + df['total_black']\n",
    "    df['sharp_ratio'] = round((df['total_sharp'] / df['total']).astype(float),2)\n",
    "    df['not_sharp_ratio'] = (1-df['sharp_ratio']).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping function to be used to aggregate game numbers. no year is seen\n",
    "def grouping_base(x):\n",
    "    d = {}\n",
    "    d['sharp_white'] = x['sharp_white'].sum()\n",
    "    d['total_white'] = x['total_white'].sum()    \n",
    "    d['sharp_black'] = x['sharp_black'].sum()\n",
    "    d['total_black'] = x['total_black'].sum()      \n",
    "    return d\n",
    "    \n",
    "def game_grouping(x):\n",
    "    d = grouping_base(x)      \n",
    "    return pd.Series(d)\n",
    "\n",
    "# grouping function with year\n",
    "def game_grouping_with_year(x):    \n",
    "    d = grouping_base(x)      \n",
    "    d['years_seen'] = x['year'].count()\n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_grouping_rating(x, sequence = 1):\n",
    "    #grouping function for ratings aggregation\n",
    "    #grouping by id, taking max rating, first seen, last seen\n",
    "    columns = { \n",
    "        'country' : 'country', \n",
    "        'rating' : 'max_rating',\n",
    "        'games' : 'games',\n",
    "        'first_seen' : 'first_seen',\n",
    "        'last_seen' : 'last_seen'}\n",
    "    \n",
    "    \n",
    "    #add a trailing index to keys\n",
    "    columns = {x: columns[x]+str(sequence) for x in columns }\n",
    "    \n",
    "    d = {}\n",
    "    d[columns['country'] ] = x['Country'].max()\n",
    "    d[columns['rating']] = x['Rating'].max()\n",
    "    d[columns['games']] = x['Games'].sum()\n",
    "    d[columns['first_seen']] = x['RatingDate'].min()\n",
    "    d[columns['last_seen']] = x['RatingDate'].max()\n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping for white id & year and black id & year respectively\n",
    "def game_grouping_white(x):\n",
    "    #grouping function for yearly game aggregation\n",
    "    #grouping by id and year, taking count sharp with white \n",
    "    \n",
    "    d = {}\n",
    "    d['sharp_white'] = x['Sharp_with_white'].sum()\n",
    "    d['total_white'] = x['Sharp_with_white'].count()    \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping for white id & year and black id & year respectively\n",
    "def game_grouping_black(x):\n",
    "    #grouping function for yearly game aggregation\n",
    "    #grouping by id and year, taking count sharp with white     \n",
    "    d = {}\n",
    "    d['sharp_black'] = x['Sharp_with_black'].sum()\n",
    "    d['total_black'] = x['Sharp_with_black'].count()    \n",
    "    return pd.Series(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9429f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player and rating consolidation functions\n",
    "\n",
    "def consolidate_player_country(row):\n",
    "    if not pd.isna(row['country1']):\n",
    "        return row['country1']\n",
    "    else:\n",
    "        return row['country2']\n",
    "\n",
    "def consolidate_player_rating(row):\n",
    "    if not pd.isna(row['max_rating1']):\n",
    "        if pd.isna(row['max_rating2']) or row['max_rating1'] > row['max_rating2']:\n",
    "            return row['max_rating1']\n",
    "        \n",
    "    return row['max_rating2']\n",
    "\n",
    "def consolidate_player_games(row):\n",
    "    if not pd.isna(row['games1']):\n",
    "        if pd.isna(row['games2']) or row['games1'] > row['games2']:\n",
    "            return row['games1']\n",
    "    return row['games2']\n",
    "    \n",
    "def consolidate_player_first_seen(row):\n",
    "    if not pd.isna(row['first_seen1']):\n",
    "        if pd.isna(row['first_seen2']) or row['first_seen1'] < row['first_seen2']:\n",
    "            return row['first_seen1']\n",
    "    return row['first_seen2']\n",
    "\n",
    "def consolidate_player_last_seen(row):\n",
    "    if not pd.isna(row['last_seen1']):\n",
    "        if pd.isna(row['last_seen2']) or row['last_seen1'] > row['last_seen2']:\n",
    "            return row['last_seen1']\n",
    "    return row['last_seen2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248746c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_format_func(value, tick_number):\n",
    "    # return % display of float\n",
    "    return str(int(value * 100))+' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying on stack column chart\n",
    "def display_age_group_charts():\n",
    "    source = age_variation[['age_at_game','sharp_ratio','not_sharp_ratio','total_sharp','total' ]].sort_values('age_at_game')\n",
    "    years = source['age_at_game']\n",
    "    sharp = source['sharp_ratio']\n",
    "    not_sharp = source['not_sharp_ratio']\n",
    "\n",
    "    total_sharp = source['total_sharp']\n",
    "    total = source['total'] # - source['total_sharp']\n",
    "\n",
    "    bar_width = 0.6\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(16,16), sharex=True)\n",
    "    axs[0].bar(years, sharp, bar_width, label = \"Sharp games' %\", color='deepskyblue', alpha=0.8)\n",
    "    axs[0].bar(years, not_sharp, bar_width,bottom=sharp, label = \"Not sharp games' %\", color='plum', alpha=0.6)\n",
    "    axs[0].legend(frameon=True)\n",
    "    axs[0].set_xlabel('age (years)')\n",
    "    axs[0].set_ylabel('ratio of sharp / not sharp games (%)')\n",
    "    axs[0].yaxis.set_major_formatter(plt.FuncFormatter(percent_format_func))\n",
    "    axs[0].grid(axis='y', linestyle='dotted', linewidth = 0.4)\n",
    "    axs[0].use_sticky_edges = False\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].tick_params(bottom=False, left=False)\n",
    "    axs[0].set_title('Ratio of sharp games from age {} to {}'.format(years.min(), years.max()), pad=5, color='#333333',\n",
    "                 weight='bold')\n",
    "\n",
    "    axs[1].bar(years, total_sharp, bar_width/2, label = \"Sharp games\", color='deepskyblue', alpha=0.8)\n",
    "    axs[1].bar(years, total, bar_width,bottom=0, label = \"Total games\", color='plum', alpha=0.6)\n",
    "    axs[1].legend(frameon=True)\n",
    "    axs[1].set_xlabel('age (years)')\n",
    "    axs[1].set_ylabel('number of games')\n",
    "    axs[1].grid(axis='y', linestyle='dotted', linewidth = 0.4)\n",
    "    axs[1].use_sticky_edges = False\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].tick_params(bottom=False, left=False)\n",
    "    axs[1].set_title('Number of games from age {} to {}'.format(years.min(), years.max()), pad=5, color='#333333',\n",
    "                 weight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_countries_chart():\n",
    "    #displaying the 10-15 countries with the sharpest style... and the top 10-15 least sharp\n",
    "\n",
    "    country_top = country_data[['sharp_ratio','name']].sort_values('sharp_ratio',ascending = False).head(10)\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(8,12), sharex=True)\n",
    "    axs[0].barh(country_top['name'], country_top['sharp_ratio'],0.8,  label = \"Sharp games' %\", color='deepskyblue', alpha=0.8)\n",
    "    axs[0].invert_yaxis()\n",
    "    axs[0].xaxis.set_major_formatter(plt.FuncFormatter(percent_format_func))\n",
    "    axs[0].set_xlabel(\"Percentage of sharp games\", labelpad=10, weight='bold', size=8)\n",
    "    axs[0].grid(axis='x', linestyle='dotted', linewidth = 0.4)\n",
    "    axs[0].use_sticky_edges = False\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].set_title('Countries playing the sharpest openings', pad=2, color='#333333',weight='bold')\n",
    "    axs[0].tick_params(axis=\"x\", which=\"major\", bottom=\"off\", top=\"off\", labelbottom=\"on\", left=\"off\", right=\"on\", labelleft=\"on\")\n",
    "\n",
    "\n",
    "    country_bottom = country_data[['sharp_ratio','name']].sort_values('sharp_ratio').head(10)\n",
    "    axs[1].barh(country_bottom['name'], country_bottom['sharp_ratio'],0.8,  label = \"Sharp games' %\", color='plum', alpha=0.8)\n",
    "    axs[1].invert_yaxis()\n",
    "    axs[1].xaxis.set_major_formatter(plt.FuncFormatter(percent_format_func))\n",
    "    axs[1].set_xlabel(\"Percentage of sharp games\", labelpad=10, weight='bold', size=8)\n",
    "    axs[1].grid(axis='x', linestyle='dotted', linewidth = 0.4)\n",
    "    axs[1].use_sticky_edges = False\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].set_title('Countries playing the least sharp openings', pad=2, color='#333333',weight='bold')\n",
    "    axs[1].tick_params(axis=\"x\", which=\"major\", bottom=\"off\", top=\"off\", labelbottom=\"on\", left=\"off\", right=\"on\", labelleft=\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_countries_classification():\n",
    "    #dispalying categories on map    \n",
    "    df_world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    ax = df_world['geometry'].boundary.plot(figsize=(10,6))\n",
    "    df_world_countries = df_world.merge(country_data, how='left', left_on='name', right_on='Map_country' )\n",
    "    df_world_countries.plot( column='category', ax=ax, cmap='Greens', \n",
    "                         legend=True, missing_kwds={'color': 'lightgrey'})\n",
    "    ax.set_title('Countries vs their players\\' sharp chess opening selection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6f7f7",
   "metadata": {},
   "source": [
    "### Data loading and generation functions \n",
    "generating or loading interim data for dataframe / pandas use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83420191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_players():\n",
    "    \"\"\"\n",
    "        Loads the list of chess players from the iput file\n",
    "        renames id to match with the id of other files\n",
    "        Cleans some data (i.e. fills empty date of birth) and calculates year born\n",
    "        \n",
    "        \n",
    "        Input:   none\n",
    "        Oiutput: dataframe of all players\n",
    "    \"\"\"\n",
    "    fn = getfilename(players_fn)\n",
    "    players_all = loadfile(fn,';')     \n",
    "            \n",
    "    #renaming IDNumber to IDnumber to be able to join on it later\n",
    "    players_all.rename(columns={'IDNumber':'IDnumber'}, inplace = True)\n",
    "    \n",
    "    #cleaning some data, i.e. date of birth and calculating age\n",
    "    #players w/o date of birth -> setting it to 0, so it can be used in non-age related, i.e. geographic analysis\n",
    "    players_all['DOB'].fillna('0000', inplace= True)\n",
    "    players_all['year_born'] = players_all['DOB'].str[0:4]\n",
    "    players_all.sort_values('year_born', ascending = False)\n",
    "    \n",
    "    return players_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ffc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rating_list(data_type):\n",
    "    \n",
    "    \"\"\"\n",
    "        Loads the rating list for players, cleans (changed decimal to be correct) and formats column types\n",
    "        Among others these files contains country information, hence will be used in geographical analysis \n",
    "        Contains rating which enables further filtering if needed        \n",
    "        \n",
    "        Input:  data_type indicating whether early or later data needs to be loaded. \n",
    "                accepted values: 'early' 'later'\n",
    "        Output: dataframe with all ratings in useable format\n",
    "    \"\"\"\n",
    "    if data_type == 'early':\n",
    "        fn = getfilename(ratings_early_fn)        \n",
    "    if data_type == 'later':\n",
    "        fn = getfilename(ratings_late_fn)\n",
    "        \n",
    "    #loads the input file, replaces decimal 'point' and returns the dataframe\n",
    "    dtypes = {'IDnumber': 'str', 'Title': 'str', 'WomensTitle':'str', 'Country':'str', 'Rating':'str', 'Games':'str', 'RatingDate': 'str' }\n",
    "    df = pd.read_csv(fn, sep=';',dtype=dtypes)\n",
    "    \n",
    "    #replacing comma with decimal\n",
    "    df['Rating'] = df['Rating'].str.replace(',','.')\n",
    "    df['Games'] = df['Games'].str.replace(',','.')\n",
    "\n",
    "    #filling rating and games nan with 0s\n",
    "    df['Rating'].fillna(0.00, inplace=True)\n",
    "    df['Games'].fillna(0.00, inplace=True)\n",
    "    \n",
    "    #converting column types    \n",
    "    df['IDnumber'] = df['IDnumber'].astype(float)\n",
    "    df['IDnumber'] = df['IDnumber'].astype(int)\n",
    "    df['Rating'] = df['Rating'].astype(float)\n",
    "    df['Games'] = df['Games'].astype(float)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eco_codes():    \n",
    "    \"\"\"\n",
    "        Loads the eco codes for opening analysis. \n",
    "        The code list contains the assessment if a given variation is considered 'sharp'\n",
    "        Y/N values are converted to 1/0 to ease calculation\n",
    "        \n",
    "        Input:  none\n",
    "        Output: dataframe with all eco codes and their assessments\n",
    "    \"\"\"\n",
    "    fn = getfilename(eco_codes_fn)\n",
    "    eco_codes = loadfile(fn) # pd.read_csv('eco_codes.csv')\n",
    "    #changing sharp values to 1 / 0 for summation\n",
    "    eco_codes.loc[eco_codes['Sharp_with_white'] == 'Y', 'Sharp_with_white'] = 1\n",
    "    eco_codes.loc[eco_codes['Sharp_with_white'] == 'N', 'Sharp_with_white'] = 0\n",
    "    eco_codes.loc[eco_codes['Sharp_with_black'] == 'Y', 'Sharp_with_black'] = 1\n",
    "    eco_codes.loc[eco_codes['Sharp_with_black'] == 'N', 'Sharp_with_black'] = 0\n",
    "    return eco_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chess_games():\n",
    "    \"\"\"\n",
    "        Loads the list of chess games, formats columns and fills na values\n",
    "        Adds a new column 'year' based on the games' date (set to 0000) if unknown\n",
    "        \n",
    "        Input:  none\n",
    "        Output: dataframe of the list of all chess games \n",
    "    \"\"\"\n",
    "    fn = getfilename(games_fn)\n",
    "    games_all = loadfile(fn) # pd.read_csv(fn, sep=',', encoding=\"utf-8\")\n",
    "    \n",
    "    games_all['ECO'] = games_all['ECO'].str[0:3]\n",
    "    #filling na values for ids and converting to int so matching can be done\n",
    "    games_all['WhiteFideId'].fillna(0.0, inplace=True)\n",
    "    games_all['BlackFideId'].fillna(0.0, inplace=True)\n",
    "    games_all['WhiteFideId'].replace(' ',0.0, inplace = True)\n",
    "    games_all['BlackFideId'].replace(' ',0.0, inplace = True)\n",
    "    games_all['WhiteFideId'] = games_all['WhiteFideId'].astype(float)\n",
    "    games_all['WhiteFideId'] = games_all['WhiteFideId'].astype(int)\n",
    "    games_all['BlackFideId'] = games_all['BlackFideId'].astype(float)\n",
    "    games_all['BlackFideId'] = games_all['BlackFideId'].astype(int)\n",
    "    \n",
    "    #adding year and merging with eco codes\n",
    "    games_all['Date'].fillna(0, inplace=True)\n",
    "    games_all['year'] = games_all['Date'].str[0:4]\n",
    "    \n",
    "    return games_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country_list():    \n",
    "    \"\"\"\n",
    "        Loads the list of countries with name and codes. \n",
    "        Names are important as geopanda uses names or codes to display data for countries\n",
    "        however, chess games seem to be having a mix of different country code standards (NOC, IOC, ISO)    \n",
    "        so the chart uses name \n",
    "        \n",
    "        Input:  none\n",
    "        Output: dataframe of the list of countries\n",
    "    \"\"\"\n",
    "    fn = getfilename(country_codes)\n",
    "    country_list = loadfile(fn)\n",
    "\n",
    "    country_list = country_list[['Country','IOC','Map_country']]\n",
    "    country_list.rename(columns={'Country':'name', 'IOC':'country'}, inplace = True)\n",
    "\n",
    "    return country_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915da7ea",
   "metadata": {},
   "source": [
    "## Players list\n",
    "loading 3 files:\n",
    "- Players.csv\n",
    "- RatingsRanksTitlesearlier.csv\n",
    "- RatingsRanksTitleslater.csv\n",
    "\n",
    "building up a single dataframe with:\n",
    "- player name\n",
    "- date of birth if known\n",
    "- year of first seen\n",
    "- year last seen\n",
    "- maximum rating over the whole period\n",
    "\n",
    "Given that the 2 ratings files are huge, an aggregated interim version will be saved.\n",
    "Those 2 files are gouped by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = getfilename(players_fn)\n",
    "#players_all = pd.read_csv(fn, ';' ,encoding = 'utf-8')\n",
    "players_all = load_players()\n",
    "players_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18695344",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_all[ (players_all['LastName'] == 'Carlsen') & (players_all['FirstName'] == 'Magnus') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d53b33c",
   "metadata": {},
   "source": [
    "## Loading early ratings list...\n",
    "this list contains 14.2 millions ratings data as person appears or can appear on every single quartely or yearly list as long as he or she is active\n",
    "\n",
    "Converting this huge list to a more manageable size, where each person (ID) has only one row:\n",
    "- ID\n",
    "- Country\n",
    "- Max rating - so games can be filtered for a given minimum or maximum level if needed\n",
    "- First seen on the list - to be able to filter people who have enough games \n",
    "- Last seen  - to be able to filter people who have enough games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading ratings list from 1970 to 2016\n",
    "\n",
    "if use_prepared_data:\n",
    "    #load data from file\n",
    "    fn = getfilename(ratings_early_grouped_fn)\n",
    "    grouped_earlier = loadfile(fn)\n",
    "else:\n",
    "    ratings_earlier = load_rating_list('early')\n",
    "    print(ratings_earlier['Rating'].sum()) #test ratings are read as numbers\n",
    "    #grouping by ID and aggregating other data points\n",
    "    grouped_earlier = ratings_earlier.groupby(['IDnumber'], sort=False).apply(apply_grouping_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_earlier.sort_values('first_seen1') #test grouping result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if set, saving the file for later reload, so may not need to regroup again\n",
    "if save_prepared_data == True:\n",
    "    fn = getfilename(ratings_early_grouped_fn)\n",
    "    savefile(fn, grouped_earlier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d111f",
   "metadata": {},
   "source": [
    "## Loading later ratings list...\n",
    "this list contains 14.2 millions ratings data as person appears or can appear on every single quartely or yearly list as long as he or she is active\n",
    "\n",
    "Converting this huge list to a more manageable size, where each person (ID) has only one row:\n",
    "\n",
    "- ID\n",
    "- Country\n",
    "- Max rating - so games can be filtered for a given minimum or maximum level if needed\n",
    "- First seen on the list - to be able to filter people who have enough games\n",
    "- Last seen - to be able to filter people who have enough games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_prepared_data:\n",
    "    #load data from file\n",
    "    fn = getfilename(ratings_later_grouped_fn)\n",
    "    grouped_later = loadfile(fn)\n",
    "else:\n",
    "    ratings_later = load_rating_list('later')\n",
    "    grouped_later = ratings_later.groupby(['IDnumber'], sort=False).apply(apply_grouping_rating,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7834a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_later.sort_values('first_seen2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f167ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if set, saving the file for later reload, so may not need to regroup again\n",
    "if save_prepared_data == True:\n",
    "    fn = getfilename(ratings_later_grouped_fn)\n",
    "    savefile(fn, grouped_later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f657a",
   "metadata": {},
   "source": [
    "## Combining player and rating lists\n",
    "combinig the player database can be essentially used for rating filtering and country mapping -> geographical display and filtering\n",
    "\n",
    "### Preparing the consolidated player list\n",
    "Preparing a list with single maximum rating and seen dates taking the min of first seen dates, the max of last seen dates and the max of ratings there is no check on the country data, if the first is set then it's taken, if not, then the second, regardless of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_earlier = grouped_earlier.reset_index()\n",
    "grouped_earlier['IDnumber'] = grouped_earlier['IDnumber'].astype(int)\n",
    "grouped_later = grouped_later.reset_index()\n",
    "grouped_later['IDnumber'] = grouped_later['IDnumber'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265e9aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using another checkpoint and stored file if set\n",
    "if use_prepared_data:\n",
    "    fn = getfilename(players_with_rating_fn)    \n",
    "    players_with_rating = loadfile(fn)\n",
    "else:\n",
    "    players_with_rating = players_all.merge(grouped_earlier, on='IDnumber', how='left')\n",
    "    players_with_rating = players_with_rating.merge(grouped_later, on='IDnumber', how='left')\n",
    "    players_with_rating['country'] = players_with_rating.apply(consolidate_player_country, axis=1)\n",
    "    players_with_rating['max_rating'] = players_with_rating.apply(consolidate_player_rating, axis=1)\n",
    "    players_with_rating['games'] = players_with_rating.apply(consolidate_player_games, axis=1)\n",
    "    players_with_rating['first_seen'] = players_with_rating.apply(consolidate_player_first_seen, axis=1)\n",
    "    players_with_rating['last_seen'] = players_with_rating.apply(consolidate_player_last_seen, axis=1)\n",
    "    #dropping old colums\n",
    "    players_with_rating.drop(columns = ['country1', 'country2', 'max_rating1', 'max_rating2', 'games1', 'games2', 'first_seen1', 'first_seen2', 'last_seen1', 'last_seen2'], inplace = True )\n",
    "    players_with_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddd20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if set, saving the consolidated player list\n",
    "if save_prepared_data == True:\n",
    "    fn = getfilename(players_with_rating_fn)\n",
    "    savefile(fn,players_with_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8e184",
   "metadata": {},
   "source": [
    "## Loading ECO file\n",
    "ECO classification file is simple table for opening variants denoted by the 3 letter ECO codes. \n",
    "For each such code some assessment has been made to see if it is 'sharp' when played by white and by black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_codes = load_eco_codes()\n",
    "eco_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18d3c4",
   "metadata": {},
   "source": [
    "## Loading chess games file\n",
    "Using caissabase 4.2 million games in pgn format can be loaded, however only a fraction of its content is really needed for this analysis. Therefore the steps to process this file are:\n",
    "- convert the file to csv by using pgn2data library\n",
    "- reusing only the 'header' information, game content, moves are discarded\n",
    "- for every game the following will be used\n",
    "    - player ids\n",
    "    - colour - if played with white or black\n",
    "    - year or date of the game\n",
    "    - ECO code or classification. This will be used to classify games to be sharp or not sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a72109",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_all = load_chess_games()\n",
    "games_all =  games_all.merge(eco_codes, on='ECO', how='left')\n",
    "#filtering out variations not in analysis\n",
    "games_all = games_all[games_all['In_analysis']=='Y']\n",
    "games_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbe533",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_white_group = games_all.groupby(['WhiteFideId','year'], sort=False).apply(game_grouping_white)\n",
    "games_white_group.reset_index(inplace = True)\n",
    "games_white_group.rename(columns={'WhiteFideId':'IDnumber'}, inplace = True)\n",
    "games_white_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4712f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_black_group = games_all.groupby(['BlackFideId','year'], sort=False).apply(game_grouping_black)\n",
    "games_black_group.reset_index(inplace = True)\n",
    "games_black_group.rename(columns={'BlackFideId':'IDnumber'}, inplace = True)\n",
    "games_black_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final merged table contains aggregated data for analysis\n",
    "# it contains grouped game summary for every year and for every player\n",
    "# given the time it takes to generates, it can be pregen-ed and loaded as well\n",
    "if use_prepared_data:\n",
    "    fn = getfilename(id_year_grouped_games)\n",
    "    games_merged_for_id_year_player = loadfile(fn)\n",
    "else:\n",
    "    #joining the 2 dataframes - outer join, there could be players with only one colour\n",
    "    games_merged_for_id_year = games_white_group.merge(games_black_group, on=['IDnumber','year'], how='outer')\n",
    "    #filtering players with no id\n",
    "    games_merged_for_id_year= games_merged_for_id_year[games_merged_for_id_year['IDnumber'] != 0 ]\n",
    "\n",
    "    #merging player data with aggregated games info. this will then be used to analyze age and country related data\n",
    "    games_merged_for_id_year_player = games_merged_for_id_year.merge(players_with_rating, on='IDnumber', how='left')\n",
    "    \n",
    "    #filtering for unknown players\n",
    "    games_merged_for_id_year_player = games_merged_for_id_year_player[games_merged_for_id_year_player['LastName'].notnull() ]\n",
    "    \n",
    "games_merged_for_id_year_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving temp file as the aggregation takes quite some time\n",
    "if save_prepared_data:\n",
    "    fn = getfilename(id_year_grouped_games)\n",
    "    savefile(fn, games_merged_for_id_year_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949eb27",
   "metadata": {},
   "source": [
    "## Question 1 - player age variation analysis\n",
    "this section filters players for date of birth, minimum games and years seen and can be used for age variation display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1553ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns, filtering on having a year_born value, filling nan\n",
    "#and calculating age at game for variation analysis\n",
    "age_variation = games_merged_for_id_year_player[['IDnumber', 'year', 'sharp_white','total_white', 'sharp_black','total_black', 'year_born']]\n",
    "age_variation = age_variation[ age_variation['year_born'] != '0000' ] \n",
    "\n",
    "age_variation['age_at_game'] = age_variation['year'].astype(int) - age_variation['year_born'].astype(int)\n",
    "age_variation.fillna(0.0, inplace = True)\n",
    "#age_variation.sort_values('year_born')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dec444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out players with not enough games or not seen for enough years\n",
    "#this is done by aggregating games for idnumber and counting the years seen. \n",
    "#once this list is there we can join it back to the above table (inner), so only those ids remain \n",
    "#that meet the filtering criteria\n",
    "included_players = age_variation.groupby(['IDnumber'], sort=False).apply(game_grouping_with_year)\n",
    "included_players['total_games'] = included_players['total_white'] + included_players['total_black']\n",
    "included_players = included_players[(included_players['years_seen'] >= minimum_years_seen) & (included_players['total_games'] >= minimum_games)]\n",
    "included_players.reset_index(inplace = True)\n",
    "#dropping unneeded columns, just need Id, then rejoin the table\n",
    "included_players = included_players['IDnumber']\n",
    "age_variation = age_variation.merge(included_players, on='IDnumber', how = 'inner')\n",
    "age_variation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc39157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dataframe still contains a lot of unneeded data for age variation (year, id, details year born)\n",
    "#need to remove those and group / sum by age\n",
    "#once grouped need to remove outliers, anything below the age of 6 and above age of 89 is to be removed\n",
    "age_variation.drop(columns = ['IDnumber', 'year', 'year_born'], inplace = True )\n",
    "age_variation = age_variation.groupby(['age_at_game'], sort=False).apply(game_grouping)\n",
    "age_variation.reset_index(inplace = True)\n",
    "\n",
    "#filtering outliers\n",
    "age_variation = age_variation[ (age_variation['age_at_game'] >5) & (age_variation['age_at_game'] <90) ]\n",
    "\n",
    "# add totals and ratios\n",
    "age_variation.reset_index(inplace=True)\n",
    "add_totals(age_variation)\n",
    "age_variation['total_sharp'] = age_variation['sharp_white'] + age_variation['sharp_black']\n",
    "age_variation['total'] = age_variation['total_white'] + age_variation['total_black']\n",
    "age_variation['sharp_ratio'] = round((age_variation['total_sharp'] / age_variation['total']).astype(float),2)\n",
    "age_variation['not_sharp_ratio'] = (1-age_variation['sharp_ratio']).astype(float)\n",
    "age_variation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ratio of sharp games for 18-23')\n",
    "youngs = age_variation[ (age_variation['age_at_game'] >= 18) & (age_variation['age_at_game'] <= 23)] .sort_values('age_at_game')\n",
    "youngs[['age_at_game','sharp_ratio', 'total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af45737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ratio of sharp games for 40-45')\n",
    "middleage = age_variation[ (age_variation['age_at_game'] >= 40) & (age_variation['age_at_game'] <= 45)] .sort_values('age_at_game')\n",
    "middleage[['age_at_game','sharp_ratio','total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_age_group_charts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8216fd1",
   "metadata": {},
   "source": [
    "## Question 2 - location style differences\n",
    "this section filters players for country only, not filtering on age, number of games etc, the only requirement is that a game has to have a known player\n",
    "\n",
    "creating 2 dataframes, one for country - year grouping and one for country only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817475d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe for country comparisons will need to have the country column filled, \n",
    "# this will unfortunately seriously decrease the available data\n",
    "# moreover for reasonable data it needs to be filtered for minimum games\n",
    "\n",
    "country_data = games_merged_for_id_year_player[ games_merged_for_id_year_player['country'].notnull() ][['sharp_white', 'sharp_black', 'total_white', 'total_black','country']]\n",
    "country_data = country_data.groupby(['country'], sort=False).apply(game_grouping)\n",
    "add_totals(country_data)\n",
    "country_data.reset_index(inplace = True)\n",
    "country_data = country_data[country_data['total'] > minimum_games_country]\n",
    "country_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11303638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading country code list, removing unneeded columns and merge it based on country code / alpha 3 iso code\n",
    "country_list = load_country_list()\n",
    "country_data= country_data.merge(country_list, on='country', how='left')\n",
    "country_data.sort_values('sharp_ratio', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44847721",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 10 countries with sharpest opening play ')\n",
    "c = country_data.sort_values('sharp_ratio', ascending = False)\n",
    "c = c[['country', 'total_sharp','total', 'sharp_ratio','name']]\n",
    "c.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a62cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 10 countries with most positional opening play ')\n",
    "c.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d435a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each country is classified into one of 5 bands based equal distribution of min / max of country values\n",
    "max_sharpness = country_data['sharp_ratio'].max()\n",
    "min_sharpness = country_data['sharp_ratio'].min()\n",
    "print('ranges is: {} to {}'.format(str(min_sharpness), str(max_sharpness)))\n",
    "\n",
    "if max_sharpness > min_sharpness:\n",
    "    #creating five bins dynamically and bin the countries based on these \n",
    "    bin_labels = [1,2,3,4,5]\n",
    "    bin_size = (max_sharpness - min_sharpness) / 5\n",
    "\n",
    "    bins = []\n",
    "    for i in range(6):\n",
    "        bins.append( round(min_sharpness + i*bin_size,2) )\n",
    "\n",
    "    print('bin size' + str(bin_size))\n",
    "    print(bins)\n",
    "    \n",
    "    #classify - bin countries\n",
    "    country_data['category'] = pd.cut(country_data['sharp_ratio'], bins = bins, labels = bin_labels )    \n",
    "else:\n",
    "    country_data['category'] = 3\n",
    "    print('cannot classify, not large enough range, setting all countries to 3')\n",
    "\n",
    "#displaying data - contains bin / category as well now\n",
    "country_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24336eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_countries_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c518651",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_countries_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5701b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas",
   "language": "python",
   "name": "geopandas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
